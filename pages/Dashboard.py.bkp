# pages/Dashboard.py
from __future__ import annotations
import sys, subprocess, json
import pandas as pd
import streamlit as st

# ---------------------------------------------------------------------
# Page config FIRST (avoid Streamlit warnings)
# ---------------------------------------------------------------------
st.set_page_config(page_title="TCO Dashboard", layout="wide")

# ---------------------------------------------------------------------
# Self-heal Plotly if missing (still recommend listing it in requirements.txt)
# ---------------------------------------------------------------------
def _ensure_plotly():
    try:
        import plotly.express as px
        return px
    except ModuleNotFoundError:
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "plotly>=5.20"])
            import plotly.express as px
            return px
        except Exception as e:
            raise RuntimeError("Plotly is required. Install with: pip install 'plotly>=5.20'") from e

px = _ensure_plotly()

# ---------------------------------------------------------------------
# Snowflake helpers
# ---------------------------------------------------------------------
try:
    from snowflake_db import fetch_df, ensure_all_views_ok
    try:
        ensure_all_views_ok()
    except Exception:
        # Non-fatal; page still works if the helper just pre-validates views
        pass
except ImportError:
    # If ensure_all_views_ok doesn't exist in your file
    from snowflake_db import fetch_df

# =========================
# Query helpers
# =========================
@st.cache_data(ttl=120, show_spinner=False)
def _choices(col: str) -> list:
    """Return distinct values for a column from VW_COSTS_AND_INVOICES."""
    sql = f"SELECT DISTINCT {col} AS V FROM VW_COSTS_AND_INVOICES ORDER BY 1"
    df = fetch_df(sql)
    if df is None or df.empty or "V" not in df.columns:
        return []
    vals = [v for v in df["V"].tolist() if v is not None and v != ""]

    key = col.upper()
    if key in ("YEAR", "PI"):
        # Treat YEAR and PI as numeric if possible
        try:
            vals = sorted({int(float(v)) for v in vals})
        except Exception:
            vals = sorted(set(map(str, vals)))
    else:
        # Case-insensitive unique while preserving representative casing
        seen = set()
        dedup = []
        for v in vals:
            k = str(v).strip().lower()
            if k and k not in seen:
                seen.add(k)
                dedup.append(v)
        vals = sorted(dedup, key=lambda x: str(x).lower())
    return vals


def _json_in_builder(where: list[str], params: list, col: str, values, as_number=False):
    if not values:
        return
    where.append(
        f"""{col} IN (
              SELECT VALUE::{'NUMBER' if as_number else 'STRING'}
              FROM TABLE(FLATTEN(input=>PARSE_JSON(%s)))
            )"""
    )
    params.append(json.dumps(values))


@st.cache_data(ttl=120, show_spinner=False)
def _fetch_filtered(years, pis, programs, teams, groups, sources, emp_types) -> pd.DataFrame:
    """
    Fetch filtered rows from VW_COSTS_AND_INVOICES using JSON array -> FLATTEN for IN filters.
    """
    where: list[str] = ["1=1"]
    params: list = []

    _json_in_builder(where, params, "YEAR", years, as_number=True)
    _json_in_builder(where, params, "PI", pis, as_number=True)
    _json_in_builder(where, params, "PROGRAMNAME", programs)
    _json_in_builder(where, params, "TEAMNAME", teams)
    _json_in_builder(where, params, "GROUPNAME", groups)
    _json_in_builder(where, params, "SOURCE", sources)
    _json_in_builder(where, params, "EMPLOYEE_TYPE", emp_types)

    sql = f"""
        SELECT
            SOURCE, YEAR, PI,
            PROGRAMID, PROGRAMNAME,
            TEAMID, TEAMNAME,
            GROUPID, GROUPNAME,
            EMPLOYEE_TYPE, AMOUNT
        FROM VW_COSTS_AND_INVOICES
        WHERE {' AND '.join(where)}
    """
    df = fetch_df(sql, tuple(params) if params else None)

    expected_cols = [
        "SOURCE","YEAR","PI","PROGRAMID","PROGRAMNAME","TEAMID","TEAMNAME",
        "GROUPID","GROUPNAME","EMPLOYEE_TYPE","AMOUNT"
    ]
    if df is None or df.empty:
        return pd.DataFrame(columns=expected_cols)

    # Ensure all expected columns exist
    for c in expected_cols:
        if c not in df.columns:
            df[c] = pd.NA

    # Coerce dtypes we chart on
    df["YEAR"] = pd.to_numeric(df["YEAR"], errors="coerce")
    df["PI"]   = pd.to_numeric(df["PI"],   errors="coerce")
    df["AMOUNT"] = pd.to_numeric(df["AMOUNT"], errors="coerce").fillna(0.0)

    # Normalize display strings
    for c in ["SOURCE","PROGRAMNAME","TEAMNAME","GROUPNAME","EMPLOYEE_TYPE"]:
        if c in df.columns:
            df[c] = df[c].astype(str).str.strip()

    return df


@st.cache_data(ttl=120, show_spinner=False)
def _fetch_feature_components(years, pis, programs, teams, groups) -> pd.DataFrame:
    """
    Pull per-feature cost components + effort from VW_TEAM_COSTS_PER_FEATURE and attach Program/Group
    so we can filter by Program/Team/Group like the main view. Then aggregate them to:
      (YEAR, PI, PROGRAMID, TEAMID, GROUPID, PROGRAMNAME, TEAMNAME, GROUPNAME)
    """
    where: list[str] = ["1=1"]
    params: list = []

    # Filters map: ADO_YEAR -> YEAR, ITERATION_NUM -> PI
    _json_in_builder(where, params, "COALESCE(v.ADO_YEAR, YEAR(v.CHANGED_AT))", years, as_number=True)
    _json_in_builder(where, params, "v.ITERATION_NUM", pis, as_number=True)
    _json_in_builder(where, params, "p.PROGRAMNAME", programs)
    _json_in_builder(where, params, "t.TEAMNAME", teams)
    _json_in_builder(where, params, "g.GROUPNAME", groups)

    sql = f"""
        SELECT
          COALESCE(v.ADO_YEAR, YEAR(v.CHANGED_AT)) AS YEAR,
          v.ITERATION_NUM                           AS PI,
          t.PROGRAMID,
          p.PROGRAMNAME,
          v.TEAMID,
          v.TEAMNAME,
          g.GROUPID,
          g.GROUPNAME,
          /* Effort (raw points) and component costs */
          CAST(v.EFFORT_POINTS AS FLOAT)           AS EFFORT_POINTS,
          CAST(v.TEAM_COST_PERPI               AS NUMBER(18,2)) AS TEAM_COST_PERPI,
          CAST(v.DEL_TEAM_COST_PERPI           AS NUMBER(18,2)) AS DEL_TEAM_COST_PERPI,
          CAST(v.TEAM_CONTRACTOR_CS_COST_PERPI AS NUMBER(18,2)) AS TEAM_CONTRACTOR_CS_COST_PERPI,
          CAST(v.TEAM_CONTRACTOR_C_COST_PERPI  AS NUMBER(18,2)) AS TEAM_CONTRACTOR_C_COST_PERPI
        FROM VW_TEAM_COSTS_PER_FEATURE v
        LEFT JOIN TEAMS t            ON t.TEAMID = v.TEAMID
        LEFT JOIN PROGRAMS p         ON p.PROGRAMID = t.PROGRAMID
        LEFT JOIN MAP_ADO_APP_TO_TCO_GROUP mag ON mag.ADO_APP = v.APP_NAME_RAW
        LEFT JOIN APPLICATION_GROUPS g ON g.GROUPID = mag.APP_GROUP
        WHERE {' AND '.join(where)}
    """
    comp = fetch_df(sql, tuple(params) if params else None)
    if comp is None or comp.empty:
        return pd.DataFrame(
            columns=[
                "YEAR","PI","PROGRAMID","PROGRAMNAME","TEAMID","TEAMNAME",
                "GROUPID","GROUPNAME",
                "EFFORT_POINTS",
                "TEAM_COST_PERPI","DEL_TEAM_COST_PERPI",
                "TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"
            ]
        )

    # Coerce types & clean
    comp["YEAR"] = pd.to_numeric(comp["YEAR"], errors="coerce")
    comp["PI"]   = pd.to_numeric(comp["PI"], errors="coerce")
    comp["EFFORT_POINTS"] = pd.to_numeric(comp["EFFORT_POINTS"], errors="coerce").fillna(0.0)
    for c in ["TEAM_COST_PERPI","DEL_TEAM_COST_PERPI","TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"]:
        comp[c] = pd.to_numeric(comp[c], errors="coerce").fillna(0.0)

    # Aggregate to merge grain (sum effort and costs)
    keys = ["YEAR","PI","PROGRAMID","TEAMID","GROUPID","PROGRAMNAME","TEAMNAME","GROUPNAME"]
    num_cols = ["EFFORT_POINTS","TEAM_COST_PERPI","DEL_TEAM_COST_PERPI","TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"]
    comp_agg = comp.groupby(keys, as_index=False)[num_cols].sum()

    return comp_agg


def _nunique_by_name(s: pd.Series | None) -> int:
    if s is None or s.empty:
        return 0
    return (
        s.dropna()
         .astype(str)
         .str.strip()
         .str.lower()
         .replace({"": pd.NA})
         .dropna()
         .nunique()
    )

# =========================
# Layout (Left: Tabs; Right: Filters)
# =========================
st.title("Cost & Invoice Dashboard")

left, right = st.columns([3, 1], gap="large")

# ---------- Filters (right) ----------
with right:
    st.subheader("Filters")

    # Load filter options
    with st.spinner("Loading filter options..."):
        years_all      = _choices("YEAR")
        pis_all        = _choices("PI")
        sources_all    = _choices("SOURCE")
        programs_all   = _choices("PROGRAMNAME")
        teams_all      = _choices("TEAMNAME")
        groups_all     = _choices("GROUPNAME")
        emp_types_all  = _choices("EMPLOYEE_TYPE")

    years      = st.multiselect("Year", years_all, default=[])
    pis        = st.multiselect("Iteration (PI)", pis_all, default=[])
    sources    = st.multiselect("Source (FEATURE / INVOICE)", sources_all, default=[])
    programs   = st.multiselect("Program", programs_all, default=[])
    teams      = st.multiselect("Team", teams_all, default=[])
    groups     = st.multiselect("Application Group", groups_all, default=[])
    emp_types  = st.multiselect("Employee Type (Feature rows)", emp_types_all, default=[])

    if st.button("Clear filters", use_container_width=True):
        st.rerun()

# ---------- Data (uses right-side selections) ----------
with st.spinner("Loading data..."):
    df_main = _fetch_filtered(years, pis, programs, teams, groups, sources, emp_types)
    # Bring component columns (features only) aggregated at (YEAR,PI,PROGRAMID,TEAMID,GROUPID)
    comp = _fetch_feature_components(years, pis, programs, teams, groups)

    # Merge components into main df so they are selectable in the Data Sheet.
    merge_keys = ["YEAR","PI","PROGRAMID","TEAMID","GROUPID","PROGRAMNAME","TEAMNAME","GROUPNAME"]
    df = df_main.merge(
        comp,
        how="left",
        on=merge_keys,
        suffixes=("", "_COMP")
    )

    # Ensure numeric post-merge
    for c in ["EFFORT_POINTS","TEAM_COST_PERPI","DEL_TEAM_COST_PERPI","TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)

with left:
    # Tabs on the left: Dashboard (charts) and Data Sheet (table)
    tab_dash, tab_sheet = st.tabs(["📊 Dashboard", "📄 Data Sheet"])

    # =========================
    # Tab 1: Dashboard
    # =========================
    with tab_dash:
        if df.empty:
            st.info("No data for the current filters.")
        else:
            # ==== KPI strip (not numbered visuals, but keep clear) ====
            total_amount = float(df["AMOUNT"].sum()) if "AMOUNT" in df else 0.0
            prog_count_name = _nunique_by_name(df.get("PROGRAMNAME"))
            team_count_name = _nunique_by_name(df.get("TEAMNAME"))

            k1, k2, k3 = st.columns(3)
            with k1:
                st.metric("Total Amount", f"${total_amount:,.0f}")
            with k2:
                st.metric("Programs", f"{prog_count_name:,}")
            with k3:
                st.metric("Teams", f"{team_count_name:,}")

            # Note if TEAMID suggests more distinct entities than names
            team_count_id = (
                int(pd.Series(dtype=object).nunique())
                if "TEAMID" not in df
                else int(pd.Series(df["TEAMID"]).nunique())
            )
            if team_count_id > team_count_name and team_count_name > 0:
                st.caption("⚠️ Multiple TEAMIDs detected for the same team name (often invoices vs features). Counting by **name** in KPIs.")

            # ---------------- Row 1 ----------------
            r1c1, r1c2 = st.columns(2)

            with r1c1:
                # ---------------- Visual 1.1 ----------------
                # Total Amount by Year (All Sources)
                if "YEAR" in df and "AMOUNT" in df:
                    d = (
                        df.groupby("YEAR", as_index=False)["AMOUNT"].sum()
                          .sort_values("YEAR", kind="mergesort")
                    )
                    fig = px.bar(d, x="YEAR", y="AMOUNT", title="[Visual 1.1] Total Amount by Year")
                    fig.update_layout(margin=dict(l=0,r=0,t=40,b=0))
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("YEAR/AMOUNT not available for chart.")

            with r1c2:
                # ---------------- Visual 1.2 ----------------
                # Amount by Year & Source (stacked)
                required = {"YEAR","SOURCE","AMOUNT"}.issubset(df.columns)
                if required:
                    d = df.groupby(["YEAR","SOURCE"], as_index=False)["AMOUNT"].sum()
                    d = d.sort_values(["YEAR","SOURCE"], kind="mergesort")
                    fig = px.bar(d, x="YEAR", y="AMOUNT", color="SOURCE", barmode="stack",
                                 title="[Visual 1.2] Amount by Year & Source")
                    fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), legend_title_text="")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("YEAR/SOURCE/AMOUNT not available for chart.")

            # ---------------- Row 2 ----------------
            r2c1, r2c2 = st.columns(2)

            with r2c1:
                # ---------------- Visual 2.1 ----------------
                # Top Programs by Amount
                if {"PROGRAMNAME","AMOUNT"}.issubset(df.columns):
                    d = (
                        df.groupby("PROGRAMNAME", as_index=False)["AMOUNT"].sum()
                          .sort_values("AMOUNT", ascending=False)
                          .head(12)
                    )
                    fig = px.bar(d, x="AMOUNT", y="PROGRAMNAME", orientation="h",
                                 title="[Visual 2.1] Top Programs by Amount")
                    fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), yaxis_title="")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("PROGRAMNAME/AMOUNT not available for chart.")

            with r2c2:
                # ---------------- Visual 2.2 ----------------
                # Top Teams by Amount (by name)
                if {"TEAMNAME","AMOUNT"}.issubset(df.columns):
                    d = (
                        df.groupby("TEAMNAME", as_index=False)["AMOUNT"].sum()
                          .sort_values("AMOUNT", ascending=False)
                          .head(12)
                    )
                    fig = px.bar(d, x="AMOUNT", y="TEAMNAME", orientation="h",
                                 title="[Visual 2.2] Top Teams by Amount")
                    fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), yaxis_title="")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("TEAMNAME/AMOUNT not available for chart.")

            # ---------------- Row 3 ----------------
            r3c1, r3c2 = st.columns(2)

            with r3c1:
                # ---------------- Visual 3.1 ----------------
                # Top Application Groups by Amount
                if {"GROUPNAME","AMOUNT"}.issubset(df.columns):
                    d = (
                        df.groupby("GROUPNAME", as_index=False)["AMOUNT"].sum()
                          .sort_values("AMOUNT", ascending=False)
                          .head(12)
                    )
                    fig = px.bar(d, x="AMOUNT", y="GROUPNAME", orientation="h",
                                 title="[Visual 3.1] Top Application Groups by Amount")
                    fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), yaxis_title="")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("GROUPNAME/AMOUNT not available for chart.")

            with r3c2:
                # ---------------- Visual 3.2 ----------------
                # Employee Type differences across Application Groups (FEATURE only • stacked)
                needed = {"SOURCE","GROUPNAME","EMPLOYEE_TYPE","AMOUNT"}
                if needed.issubset(df.columns):
                    d = df[(df["SOURCE"] == "FEATURE") & df["GROUPNAME"].notna() & df["EMPLOYEE_TYPE"].notna()].copy()
                    if not d.empty:
                        top_n = st.slider(
                            "Top Application Groups to show (by total Feature Amount)",
                            5, 40, 20, key="top_groups_emp_type"
                        )
                        totals = d.groupby("GROUPNAME", as_index=False)["AMOUNT"].sum().sort_values("AMOUNT", ascending=False)
                        keep = set(totals.head(top_n)["GROUPNAME"].tolist())
                        d = d[d["GROUPNAME"].isin(keep)]
                        g = d.groupby(["GROUPNAME","EMPLOYEE_TYPE"], as_index=False)["AMOUNT"].sum()
                        # Sort groups by total for cleaner display order
                        order = totals[totals["GROUPNAME"].isin(keep)].sort_values("AMOUNT", ascending=True)["GROUPNAME"].tolist()
                        fig = px.bar(
                            g,
                            x="AMOUNT",
                            y="GROUPNAME",
                            color="EMPLOYEE_TYPE",
                            orientation="h",
                            category_orders={"GROUPNAME": order},
                            title="[Visual 3.2] Employee Type by Application Group (Features • Stacked)"
                        )
                        fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), legend_title_text="Employee Type")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("No feature rows with Employee Type data in current selection.")
                else:
                    st.info("Required columns for Employee Type chart are missing.")

            # ---------------- Row 4 ----------------
            r4c1, r4c2 = st.columns(2)

            with r4c1:
                # ---------------- Visual 4.1 ----------------
                # Feature Cost by Year & PI (stacked)
                if {"SOURCE","PI","YEAR","AMOUNT"}.issubset(df.columns):
                    d = df[(df["SOURCE"] == "FEATURE") & df["PI"].notna()].copy()
                    if not d.empty:
                        d["PI"] = d["PI"].astype(int).astype(str)
                        d2 = d.groupby(["YEAR","PI"], as_index=False)["AMOUNT"].sum()
                        fig = px.bar(d2, x="YEAR", y="AMOUNT", color="PI",
                                     title="[Visual 4.1] Feature Cost by Year & PI (Stacked)")
                        fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), legend_title_text="PI")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("No PI data in current selection.")
                else:
                    st.info("PI/YEAR/AMOUNT not available for chart.")

            with r4c2:
                # ---------------- Visual 4.2 ----------------
                # SOURCE Split (Feature vs Invoice) • donut
                if {"SOURCE","AMOUNT"}.issubset(df.columns):
                    d = df.groupby("SOURCE", as_index=False)["AMOUNT"].sum()
                    fig = px.pie(d, values="AMOUNT", names="SOURCE", hole=0.5,
                                 title="[Visual 4.2] SOURCE Split (Feature vs Invoice)")
                    fig.update_layout(margin=dict(l=0,r=0,t=40,b=0))
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("SOURCE/AMOUNT not available for chart.")

            # ---------------- Row 5 ----------------
            c5l, c5r = st.columns(2)

            with c5l:
                # ---------------- Visual 5.1 ----------------
                # Feature Cost Components by Year (TEAM/DELIVERY/CS/C) • stacked
                needed = {"YEAR","TEAM_COST_PERPI","DEL_TEAM_COST_PERPI",
                          "TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"}
                if needed.issubset(df.columns):
                    d = df[df["SOURCE"] == "FEATURE"].copy()
                    if not d.empty:
                        by_year = (
                            d.groupby("YEAR", as_index=False)[
                                ["TEAM_COST_PERPI","DEL_TEAM_COST_PERPI",
                                 "TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"]
                            ].sum()
                        )
                        m = by_year.melt(id_vars="YEAR", var_name="Component", value_name="Amount")
                        comp_map = {
                            "TEAM_COST_PERPI": "TEAM (PI fixed eq-split)",
                            "DEL_TEAM_COST_PERPI": "DELIVERY (effort share)",
                            "TEAM_CONTRACTOR_CS_COST_PERPI": "CONTRACTOR_CS (effort share)",
                            "TEAM_CONTRACTOR_C_COST_PERPI": "CONTRACTOR_C (effort share)",
                        }
                        m["Component"] = m["Component"].map(comp_map)
                        fig = px.bar(m, x="YEAR", y="Amount", color="Component",
                                     title="[Visual 5.1] Feature Cost Components by Year (Stacked)")
                        fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), legend_title_text="")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("No feature rows with components in current selection.")
                else:
                    st.info("Component columns not available for chart.")

            with c5r:
                # ---------------- Visual 5.2 ----------------
                # Feature Cost Components by PI (TEAM/DELIVERY/CS/C) • stacked
                needed = {"PI","TEAM_COST_PERPI","DEL_TEAM_COST_PERPI",
                          "TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"}
                if needed.issubset(df.columns):
                    d = df[(df["SOURCE"] == "FEATURE") & df["PI"].notna()].copy()
                    if not d.empty:
                        d["PI"] = d["PI"].astype(int)
                        by_pi = (
                            d.groupby("PI", as_index=False)[
                                ["TEAM_COST_PERPI","DEL_TEAM_COST_PERPI",
                                 "TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"]
                            ].sum()
                        )
                        m = by_pi.melt(id_vars="PI", var_name="Component", value_name="Amount")
                        comp_map = {
                            "TEAM_COST_PERPI": "TEAM (PI fixed eq-split)",
                            "DEL_TEAM_COST_PERPI": "DELIVERY (effort share)",
                            "TEAM_CONTRACTOR_CS_COST_PERPI": "CONTRACTOR_CS (effort share)",
                            "TEAM_CONTRACTOR_C_COST_PERPI": "CONTRACTOR_C (effort share)",
                        }
                        m["Component"] = m["Component"].map(comp_map)
                        fig = px.bar(m, x="PI", y="Amount", color="Component",
                                     title="[Visual 5.2] Feature Cost Components by PI (Stacked)")
                        fig.update_layout(margin=dict(l=0,r=0,t=40,b=0), legend_title_text="Component")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("No PI/component data in current selection.")
                else:
                    st.info("Component columns not available for chart.")

    # =========================
    # Tab 2: Data Sheet
    # =========================
    with tab_sheet:
        st.write("Use this sheet to validate rows/columns from `VW_COSTS_AND_INVOICES` and feature components from `VW_TEAM_COSTS_PER_FEATURE`.")

        if df.empty:
            st.info("No rows match the current filters.")
        else:
            # Quick KPIs for the sheet
            c1, c2, c3 = st.columns(3)
            with c1:
                st.metric("Rows", f"{len(df):,}")
            with c2:
                st.metric("Distinct Programs (by name)", f"{_nunique_by_name(df.get('PROGRAMNAME')):,}")
            with c3:
                st.metric("Sum(Amount)", f"${df['AMOUNT'].sum():,.0f}")

            # Column selector (includes EFFORT_POINTS and components)
            default_cols = [
                "SOURCE","YEAR","PI","PROGRAMNAME","TEAMNAME","GROUPNAME",
                "EMPLOYEE_TYPE","AMOUNT",
                "EFFORT_POINTS",
                "TEAM_COST_PERPI","DEL_TEAM_COST_PERPI",
                "TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"
            ]
            all_cols = list(df.columns)
            cols = st.multiselect(
                "Columns to display",
                options=all_cols,
                default=[c for c in default_cols if c in all_cols],
            )

            # Optional quick group-by for validation
            with st.expander("Aggregate preview (optional)"):
                group_cols = st.multiselect(
                    "Group by columns",
                    options=[c for c in all_cols if c not in {"AMOUNT","EFFORT_POINTS","TEAM_COST_PERPI","DEL_TEAM_COST_PERPI","TEAM_CONTRACTOR_CS_COST_PERPI","TEAM_CONTRACTOR_C_COST_PERPI"}],
                    default=[]
                )
                if group_cols:
                    agg = (
                        df.groupby(group_cols, as_index=False)
                          .agg(
                              ROWS=("AMOUNT","size"),
                              AMOUNT_SUM=("AMOUNT","sum"),
                              EFFORT_POINTS_SUM=("EFFORT_POINTS","sum"),
                              TEAM_COST_PERPI_SUM=("TEAM_COST_PERPI","sum"),
                              DEL_TEAM_COST_PERPI_SUM=("DEL_TEAM_COST_PERPI","sum"),
                              TEAM_CONTRACTOR_CS_COST_PERPI_SUM=("TEAM_CONTRACTOR_CS_COST_PERPI","sum"),
                              TEAM_CONTRACTOR_C_COST_PERPI_SUM=("TEAM_CONTRACTOR_C_COST_PERPI","sum"),
                          )
                    )
                    st.dataframe(agg, use_container_width=True, hide_index=True)

            # Data table
            st.dataframe(df[cols] if cols else df, use_container_width=True, hide_index=True)

            # Download
            csv = (df[cols] if cols else df).to_csv(index=False).encode("utf-8")
            st.download_button(
                "Download filtered data as CSV",
                data=csv,
                file_name="dashboard_filtered_data.csv",
                mime="text/csv",
                use_container_width=True,
            )
